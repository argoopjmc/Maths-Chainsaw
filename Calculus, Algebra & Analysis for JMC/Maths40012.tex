
\documentclass[12pt]{report}
\usepackage[thinc]{esdiff} % for typesettign derivatives
\usepackage{amsthm} % provides an enhanced version of LaTex's \newtheorem command
\usepackage{mdframed} % framed environments that can split at page boundaries
\usepackage{enumitem} % bulletin points or other means of listing things
\usepackage{amssymb} % for AMS symbols
\usepackage{amsmath} % so as to use align

\theoremstyle{definition}
\mdfdefinestyle{defEnv}{%
  hidealllines=false,
  nobreak=true,
  innertopmargin=-1ex,
}

\pagestyle{headings}
\author{Marie Amellie, Frank Berkshire}
\title{Calculus, Algebra, and Analysis for JMC}
\begin{document}
\maketitle
\tableofcontents

\chapter{Group theory}

Study of the simplest algebraic structure on a set.

\section{Binary operations and groups}

\newmdtheoremenv[style=defEnv]{theorem}{Definition}
\begin{theorem}
    \emph{Set} is a collection of distinct elements. Let $G$ be a set.
    \textbf{\emph{Binary operation on G}} is a function\[
        *: G \times G \rightarrow G \textnormal{(Closure is included)}
    \]
\end{theorem}

\newtheorem{ex}[theorem]{Example}
\begin{ex}
    \;
    
    \begin{itemize}
        \item $(\mathbb{N}, +), (\mathbb{Z}, +), (\mathbb{R}, \cdot)$
        \item $(\mathbb{N}, -)$ not a binary op. Not closed.
        \item $g, h \in G, g * h = h$
        \item Find a certain $c \in G$, define $g*h = c \;\forall g, h \in G$
    \end{itemize}
    
\end{ex}

\begin{ex}
    Cayley table: Draw a table of all the possible binary operations on a set.
    How many possible binary operations on a finite set with $n$ elements?
    In general, there are $\infty$-many biniary operatiions. In this case, there are $n^{n^2}$ possible binary operations.
    \emph{In general, $g_i * g_j \neq g_j * g_i$} (Not commutative!)
    
\end{ex}

\newmdtheoremenv[style=defEnv]{Associativity}[theorem]{Definition}
\begin{Associativity}
    A binary operation $*$ on a set $G$ is called associative if\[
        (g*h)*k = g*(h*k) \;\forall g,h,k \in G
    \]
\end{Associativity}

\begin{ex}
    \;

    \begin{itemize}
        \item $+$ on $\mathbb{N, Z, R}$? Yes
        \item $-$ on $\mathbb{R}$? No
        \item $g*h = g^{h}$ on $\mathbb{N}$? No
    \end{itemize}
    
\end{ex}

\newmdtheoremenv[style=defEnv]{commutative}[theorem]{Definition}
\begin{commutative}
    A binary operation is called commutative if \[
        \forall g, h \in G, g * h = h * g
    \]
\end{commutative}

\begin{ex}
    \;

    \begin{itemize}
        \item $+, \cdot$ on $\mathbb{N, Z, R, C}$
        \item matrix multiplication ($AB \neq BA$ in general for $A, B$ in $M(\mathbb{R}^{n})$)
        \item let $g, h \in \mathbb{R}$, $g * h = 1 + g \cdot h$: commutative but \emph{not associative}!
    \end{itemize}
    
\end{ex}

\newmdtheoremenv[style=defEnv]{identity element}[theorem]{Definition}
\begin{identity element}
    Let $(G, *)$ be a set. An element $e$ is called \emph{left identity} (respectively \emph{right identity}) if:\[
        e * g = g (\textnormal{resp.}\; g * e = g) \;\forall\; g \in G
    \]
    \underline{Caution}: There might be \emph{many} left/right identities or none.
\end{identity element}

\begin{ex}
    \;

    \begin{enumerate}
        \item let $(G,*)$ be a set with $g*h:=g$.
            Find the left/right identities.

            $\infty$-many (or equal to the number of elements)
            right identities since $h$ satisfies definition $\forall h$.
            No left identities: wanted $e * g = g = e$ by definitioin of $*$ (\emph{unless only one element}).
        \item $(G, *)$, $g*h = 1 + gh$. 
            Ex: No right/left identities.
    \end{enumerate}
\end{ex}

Idea: We want a good unique identity.
\newmdtheoremenv[style=defEnv]{unique identity}[theorem]{Theorem}
\begin{unique identity}
    let $(G, *)$ be set, such that $*$ has both a left identity $e_1$ \emph{and}
    a right identity $e_2$, then\[
        e_1 = e_2 =: e \quad \textnormal{and} \quad e \textnormal{ is unique.}
    \]
\end{unique identity}

\begin{proof}
    \;

    \begin{itemize}
            \item $e_1 = e_2$
    \[
    \Rightarrow \left\{
        \begin{array}{l}
        e_1 * g = g \Rightarrow e_1 * e_2 = e_2 \\
        g * e_2 = g \Rightarrow e_1 * e_2 = e_1
    \end{array}
\right\} \forall\,g \in G \Rightarrow\,e_1 = e_2%chktex 1
\]
            \item Unicity: Assume there exists another identity $e'$.\[
                \Rightarrow e' * g = g * e' = g
            \]\[
                e' * g = e' * e = e
            \]\[
                g * e' = e * e' = e'
            \]Therefore \[
                e = e'
            \]
    \end{itemize}
    
\end{proof}
As soon as you get one left and one right identity, you have a unique identity $e$.

\newmdtheoremenv[style=defEnv]{inverse}[theorem]{Definition}
\begin{inverse}
    let $(G,*)$ be a set. Let $g \in G$.
    An element $h \in G$ is called left (resp.\ right) inverse if\[
        h * g = e \;(\textnormal{resp. } g * h = e)
    \]
    \underline{Caution}: Again inverses might not exist, 
    there might be many, or \emph{not} the same on both sides.
\end{inverse}

\begin{ex}
    \,

    \begin{enumerate}[label = (\arabic*)]
        \item $(\mathbb{N}, \cdot)$
            1 has an inverse, otherwise \emph{no} inverse.
        \item Find a binary operation on a set of 4 elements with left/right inverses
            not the same but identity $e$.
    \end{enumerate}
    
\end{ex}

\newmdtheoremenv[style=defEnv]{equal left right inverse}[theorem]{Theorem}
\begin{equal left right inverse}
    Let $(G, *)$ be a set with associative binary operation and identity $e$.
    Then if $h_1$ is left inverse, and $h_2$ is right inverse, then\[
        h_1 = h_2 = g^{-1} \;\textnormal{ and \emph{it is unique}}
    \]
\end{equal left right inverse}

\begin{proof}
    \;

    \begin{itemize}
            \item $h_1 = h_2$

                $h_1 * g = e, g * h_2 = e$. Therefore\[
                    h_2 = e * h_2 = (h_1 * g) * h_2 = h_1 * (g * h_2) = e = h_1
                \]
            \item unicity: Assume $\exists g'^{-1}$ another inverse.\[
                    g'^{-1} = e * g'^{-1} = (g^{-1} * g) * g'^{-1} 
                    = g^{-1} * (g * g'^{-1}) = g^{-1} * e = g^{-1}
            \]
    \end{itemize}
\end{proof}

\newmdtheoremenv[style=defEnv]{Group Definition}[theorem]{(Group) Definition}
\begin{Group Definition}
    A set $(G,*)$ wth binary operatioin $*$ is called a \emph{group} if:
    \begin{enumerate}[label = (\arabic*)]
        \item $*$ is associative
        \item $\exists e \in G$ an identity $\forall g \in G$
        \item All elements $g \in G$ have an inverse $g^{-1}$
    \end{enumerate}
    \underline{Attention}: The identity and inverses are \emph{unique} by our previous results.
    
\end{Group Definition}

\begin{ex}
    \;

    \begin{itemize}
        \item $(\mathbb{Z}, +), (\mathbb{Z}_n, +)$ are groups.
        \item $(\mathbb{N}, +)$ not a group $\Rightarrow$ no inverses.
        \item $(\mathbb{C}, \cdot)$ not a group (0 has no multiplicative inverse),
            but $(\mathbb{C}^{*}, \cdot)$ is. ($\mathbb{C}^{*} = \mathbb{C}\backslash \{0\}$)
        \item $(G = \{e\}, *)$ with $e * e = e$ is a group called the \emph{trivial group}.
        \item Empty set $\varnothing$ is not a group (No identity element.)
    \end{itemize}
    
\end{ex}

\newmdtheoremenv[style=defEnv]{finite group}[theorem]{Definition}
\begin{finite group}
    Let $G$ be a group. It is called \underline{finite} if it has finitely many elements.
    
    \underline{Notation}: $|G| = n$ (number of elements)

    If $|G| = \infty$, the $G$ is called an infinite group.
\end{finite group}

\begin{ex}
    \;

    \begin{itemize}
        \item the trivial group is finite, $|G| = 1$
        \item let $G = \{1, -1, i, -i\} \subset \mathbb{C}$, with $* = \cdot$.
            Is it a group? Yes. Check associativity, identity, and inverses.
    \end{itemize}
    
\end{ex}

\newmdtheoremenv[style=defEnv]{abelian group}[theorem]{(Abelian Group) Definition}
\begin{abelian group}
    A group is called \emph{Abelian} if $*$ is commutative.
\end{abelian group}

\begin{ex}
    \;

    \begin{itemize}
            \item previous example, trvial group, $(\mathbb{Z}, +), (\mathbb{C}^{*}, \cdot)$
            \item let $GL(\mathbb{R}^{n})$ be the set of all invertible $n \times n$ matrices, $* = $ matrix multiplication.
                It is associative: $(AB)C = A(BC)$;
                It has identity: $I_n$.
                It has inverses: yes since we asked for it.
                So this is a group of matrices.
                But this is not Abelian since $AB \neq BA$.
            \item let $G$ be the set of \emph{invertible} functions with $* = \circ$, the composition of functions.
                Identity is $F(x) = x$; they are associative, invertible, but \emph{not Abelian}.
    \end{itemize}
    
\end{ex}

\section{Consequences of the axioms of group}



\chapter{Applied Mathematical Methods}

\section{Differential Equations}

\subsection{Definitions and examples}

\newmdtheoremenv[style=defEnv]{ODE}[theorem]{Definition}
\begin{ODE}
    An \emph{ordinary differential equation} (ODE) for $y(x)$ is an equation involving \underline{derivatives} of $y$.
    \begin{equation}\label{ODE:1}
        f(x, y, \frac{\mathrm{d} y}{\mathrm{d}x}, \frac{\mathrm{d}^{2} y}{\mathrm{d}x^{2}}, \ldots,
        \frac{\mathrm{d}^{n} y}{\mathrm{d}x^{n}}) = 0
        \end{equation}
    \[
        \frac{\mathrm{d}^{n} y}{\mathrm{d}x^{n}} = 
        F(x, y, \frac{\mathrm{d} y}{\mathrm{d}x}, \ldots, \frac{\mathrm{d}^{n-1} y}{\mathrm{d}x^{n-1}})
    \]
    and we seek a solution (or solutions) for $y(x)$ satisfying the equations.
    (If there are more independent variables then we have a partial differential equation (PDE).)
\end{ODE}

\newmdtheoremenv[style=defEnv]{order and power}[theorem]{Definition}
\begin{order and power}
    \;

    \emph{Order} is the order of the highest derivative present.

    \emph{Degree} is the power of the highest derivative when fractional powers have been removed.

    \emph{\textbf{Linear} differential equation} is a differential equation that is defined by a \emph{linear polynomial}
    in the unknown function and its derivative in each term of equation\eqref{ODE:1}.
\end{order and power}

\begin{ex}
    \;

    \begin{enumerate}[label = (\alph*)]
        \item \underline{Particle moving along a line} with a given force $\rightarrow x(t)$ position
            as function of time $t$.\[
                \frac{\mathrm{d}^{2} x}{\mathrm{d}t^{2}} = f\left(t, x, \frac{\mathrm{d} x}{\mathrm{d}t} \right) 
            \]e.g.\[
                \frac{\mathrm{d}^{2}x}{\mathrm{d}t^{2}} = -\omega^{2}x - 2k\frac{\mathrm{d} x}{\mathrm{d}t} 
            \]
            The first term is regarding the restoring force,
            while the second term is regarding the damping/friction.
            The function is of order 2, degree 1, and linear.

        \item \underline{Radius of curvature} of a curve

            It can be shown that \[
                R(x,y) = \frac{{\left[1 + {\left(\frac{\mathrm{d} y}{\mathrm{d}x} \right)}^{2}\right]}^{\frac{3}{2}}}
                {\frac{\mathrm{d}^{2}y}{\mathrm{d}x^{2}} }
            \]
            The function is of order 2 and degree 2.

        \item \underline{Simple growth and decay}\[
            \frac{\mathrm{d} Q}{\mathrm{d}t} = kQ
        \]
        The function is of order 1, degree 1, and linear.\ e.g. 
        \begin{enumerate}[label = (\arabic*)]
            \item $k > 0$. $Q$ as the quantity of money, and $k = (1 + \frac{r}{100})$, and $r$ being the rate of interest.
            \item $k < 0$. $Q$ as the amount of radioactive material, and $k$ as the decay rate.
        \end{enumerate}
        Hence, obviously $Q(t) = Q_0e^{kt}$ where $Q_0 = Q(0)$ at $t = 0$.

    \item \underline{Population dynamics}

        $P(t)$ as population over time and $F(t)$ as food over time, with
        \begin{equation}\label{ODE:2}
                \frac{\mathrm{d} P}{\mathrm{d}t} = aP (a>0)
            \end{equation}
            
        \[
        \frac{\mathrm{d} F}{\mathrm{d}t} = c (c>0)
        \]
        These two equations form a linear system, with both being of order 1, degree 1.
        
        So $P(t) = P_0 e^{at}, F(t)=ct + F_0$.
        Misery! Population outgrows food supply.

        Pierre Verhulst (1845) replaced $a$ in equation\eqref{ODE:2} with $(a - bP)$
        so that growth decreases as $P$ increases:
        \begin{equation}\label{ODE:3}
            \frac{\mathrm{d} P}{\mathrm{d}t} = aP - bP^{2}
        \end{equation}
        This is in fact a \emph{logistic ODE}, with order 1, degree 1, and nonlinear.

        \underline{Note}: Equation\eqref{ODE:3} is \emph{separable}. Alternatively we can note that 
        equation\eqref{ODE:3} is an example of a \textit{Bernoulli differential equation}
        \begin{equation}\label{ODE:6}
            \frac{\mathrm{d} y}{\mathrm{d}x} + F(x)y = H(x)y^{n}
        \end{equation}
        with $n\neq 0,1$
        Substitution on $z(x) = {(y(x))}^{1-n} \Rightarrow$ a \emph{linear} equation for 
        $z(x) \rightarrow $ solution. (See below)

    \item \underline{Predator-Prey System}

        $x(t)$ as prey and $y(t)$ as predators, we have
        \begin{equation}\label{ODE:4}
            \frac{\mathrm{d} x}{\mathrm{d}t} = ax - bxy,\quad
            \frac{\mathrm{d} y}{\mathrm{d}t} = -cy + \hat{d}xy
        \end{equation}
        \underline{Note}: Equation\eqref{ODE:4} is \emph{separable} when written in principle\[
            \frac{\mathrm{d} y}{\mathrm{d}x} = \frac{\frac{\mathrm{d} y}{\mathrm{d}t} }
            {\frac{\mathrm{d} x}{\mathrm{d}t} } \Rightarrow y(x) \Rightarrow x(t), y(t)
        \]
        This is of order 1, degree 1, and a nonlinear system.
        
    \item \underline{Combat Model System} 
        \begin{equation}\label{ODE:5}
            \frac{\mathrm{d}x}{\mathrm{d}t} = -ay, \quad
            \frac{\mathrm{d}y}{\mathrm{d}t} = -bx
        \end{equation}
        This is of order 1, degree 1, and linear system.

        \underline{Note}: Again equation\eqref{ODE:5} is \emph{separable} when written as
        $\frac{\mathrm{d} y}{\mathrm{d}x} = \frac{bx}{ay} \Rightarrow y(x) \Rightarrow x(t), y(t)$
    \end{enumerate}
    
\end{ex}

In general the solution of a differential equation of order $n$
contains a number $n$ of \emph{arbitrary constants}. 
This general solution can be specialised to a particular solution by
assigninig definite values to these constants.

\begin{ex}
    \;

\begin{enumerate}[label = (\alph*)]
    \item Family or parabolae $y = Cx^{2}$ as constant $C$ takes different values.

        On a particular curve of the family $\frac{\mathrm{d}y}{\mathrm{d}x} = 2Cx$.
        By substitutiion, eliminate $C \Rightarrow \frac{\mathrm{d}y}{\mathrm{d}x} = \frac{2y}{x}$.
        This is a geometrical statement about slopes.

        \underline{Note}: 1st order differential equation $\leftrightarrow$ 1 arbitrary constant in general solution.

    \item \[
        \left.
            \begin{align*}
                x &= A\sin{\omega t} + B\cos{\omega t} \\
                \frac{\mathrm{d}x}{\mathrm{d}t} & = A\omega\cos{\omega t} - B\omega\sin{\omega t} \\
                \frac{\mathrm{d}^{2}x}{\mathrm{d}t^{2}}
                                                & = -A\omega^{2}\sin{\omega t} - B\omega^{2}\cos{\omega t}
            \end{align*}
        \right\} \Rightarrow\frac{\mathrm{d}^{2}x}{\mathrm{d}t^{2}} + \omega^{2} x = 0
    \]
    \underline{Note}: 2nd order differential equation $\leftrightarrow$ 2 arbitrary constants in general solution.

\end{enumerate}
    
\end{ex}

Of course it's the reverse of this process we normally want to perform
in order to get the general solution. We then often need a particular solution
--- which satisfieis certain other conditions --- \emph{boundary} or \emph{initial condition}.
These allow us to find the arbitrary constants in the solutions.

\subsection{First Order Differential Equations}

\subsubsection{Properties and approaches}

There are essentially 4 types we can solve \emph{analytically}:
\begin{itemize}
        \item \emph{\textbf{separable}} 
        \item \emph{\textbf{homogeneous}} 
        \item \emph{\textbf{linear}} 
        \item \emph{\textbf{exact}} (in Chapter ``Partial Differentiation and Multivariable Calculus'' later)
\end{itemize}

Let's look at them one by one:
\begin{enumerate}[label = (\alph*)]
    \item \textbf{\underline{Separable}} \[
            \frac{\mathrm{d}y}{\mathrm{d}x} = G(x) \cdot H(y)
    \] Solve by rearrangement and integration\[
    \int_{}^{y} \frac{\mathrm{d}y}{H(y)} = \int_{}^{x} G(x)\mathrm{d}x
    \]
    E.g. \[
        \begin{align*}
            \frac{\mathrm{d}y}{\mathrm{d}x} & = xy^{2}e^{-x} \\
            \int \frac{1}{y^{2}} \mathrm{d}y & = \int xe^{-x} \mathrm{d}x \\
            -\frac{1}{y} & = -xe^{-x} - e^{-x} + C
        \end{align*}
    \]
    Or singular solution $y = 0$.

    If we want the particular solution which passes through $x = 1, y = 1$, then of course we need \[
        C = -1 + 2e^{-1} \quad \textnormal{and} \quad \frac{1}{y} = (x+1)e^{-x} + 1 - 2e^{-1}
    \]

\item \textbf{\underline{Homogeneous}} \[
        \frac{\mathrm{d}y}{\mathrm{d}x} = f\left(\frac{y}{x}\right) 
    \]Substitution $\frac{y}{x} = u(x)$,
    i.e.\ a new dependent variable, \[
        \begin{align*}
            \frac{\mathrm{d}y}{\mathrm{d}x} = u + x\frac{\mathrm{d}u}{\mathrm{d}x} & (= f(u)) 
            \quad \textnormal{\textbf{\emph{(Remember!)}}} \\
            f(u) - u & = \frac{x\mathrm{d}u}{\mathrm{d}x} \\
            \int \frac{\mathrm{d}u}{f(u) - u} & = \int \frac{\mathrm{d}x}{x} \\
            \vdots
        \end{align*}
    \]
    E.g. 
    \begin{enumerate}[label = (\roman*)]
        \item \[
            \begin{align*}
                x^{2} \frac{\mathrm{d}y}{\mathrm{d}x} + xy - y^{2} & = 0 \\
                \frac{\mathrm{d}y}{\mathrm{d}x} & = {\left(\frac{y}{x}\right)}^{2} - \frac{y}{x} \\
                \frac{\mathrm{d}u}{\mathrm{d}x} & = \frac{u^{2} - 2u}{x} \\
                \vdots
            \end{align*}
        \]
    \item \[
        \frac{\mathrm{d}y}{\mathrm{d}x} = \frac{x + y - 3}{x - y + 1}
    \]This does not look homogeneous as it stands, but can be made so by substituting
    $x= 1 + X, y = 2 + Y$, and the expression becomes\[
        \frac{\mathrm{d}Y}{\mathrm{d}X} = \frac{X + Y}{X - Y} 
        = \frac{1 + \left(\frac{Y}{X}\right)}{1 - \left(\frac{Y}{X}\right)}
    \]Then let $\frac{Y}{X} = u(X)$,\[
    \Rightarrow \int \left(\frac{1-u}{1+u^2}\right) \mathrm{d}u = \int \frac{\mathrm{d}X}{X}
    \]
    Eventually, the equation becomes\[
        \tan^{-1}{\frac{Y}{X}} - \frac{1}{2} \ln{\left(1 + \frac{Y^2}{X^2}\right)} 
        = \ln{X} + C
    \]\[
    \tan^{-1}{\left(\frac{y-2}{x-1}\right)} - \frac{1}{2} \ln{\left[{(x-1)}^{2} + {(y-2)}^{2}\right] } = C
    \]
    \underline{Note}: If we have e.g. $\frac{\mathrm{d}y}{\mathrm{d}x} = \frac{x + y - 3}{2(x + y) - 7}$,
    then substitute $v(x) = x + y$ will work!
    \end{enumerate}

\item \textbf{\underline{Linear}} \[
        \frac{\mathrm{d}y}{\mathrm{d}x} + F(x)y = G(x)
        \]
        1st power only for $y$ and $\frac{\mathrm{d}y}{\mathrm{d}x} $.
        We apply an \emph{integrating factor} $R(x)$: \[
R(x) = \exp{\left[\int_{}^{x} F(x)\mathrm{d}x\right] }
\] This allows us to form the expression\[
\frac{\mathrm{d}}{\mathrm{d}x} \left[y \exp{\left(\int_{}^{x} F(x)\mathrm{d}x\right) }\right] 
= G(x) \exp{\left(\int_{}^{x} F(x)\mathrm{d}x\right) }
\]and then integrate\ldots

E.g. \[
    (x+2) \frac{\mathrm{d}y}{\mathrm{d}x} - 4y = {(x+2)}^{6}
\]\[
\frac{\mathrm{d}y}{\mathrm{d}x} - \frac{4}{x+2} = {(x + 2)}^{5}
\]\[
\Rightarrow F(x) = -\frac{4}{x+2}, G(x) = {(x + 2)}^{5}
\]Therefore,\[
R(x) = \exp{\left[-\int_{}^{x} \left(\frac{4}{x+2}\right) \mathrm{d}x\right] }
= \cdots = K{(x+2)}^{-4}
\]Subsequently, take $K = 1$ W.L.O.G.:\[
{(x+2)}^{-4}\frac{\mathrm{d}y}{\mathrm{d}x} - 4{(x+2)}^{-5} y
= \frac{\mathrm{d}}{\mathrm{d}x} \left[y{(x+2)}^{-4}\right] = x + 2
\]As such,\[
y{(x + 2)}^{-4} = \frac{1}{2}x^{2} + 2x + C \quad \textnormal{(Put $C$ at the right time!)}
\]\[
y(x) = \left(\frac{1}{2}x^{2 + 2x + C}\right) {(x + 2)}^{4}
\]
(So e.g. $y(0) = 8 \Rightarrow C = \frac{1}{2}$)
\end{enumerate}

\subsubsection{Novelties!}

\begin{enumerate}[label = (\roman*)]
    \item Bernoulli equation (See Equation\eqref{ODE:6})
        \\A nonlinear equation rendered linear by a substitution $u = y^{1-n}$\ldots

    \item E.g.\[
        \frac{\mathrm{d}y}{\mathrm{d}x} = \frac{1}{x + e^{y}}
    \]It is \underline{nonlinear} for $y(x)$ but \underline{linear}  for $x(y)$:\[
        \frac{\mathrm{d}x}{\mathrm{d}y} - x = e^{y} \Rightarrow \ldots
    \]
\end{enumerate}

\subsection{`Special' Second Order Differential Equations}

\newmdtheoremenv[style=defEnv]{General 2nd order ODE}[theorem]{Definition}
\begin{General 2nd order ODE}
    General Explicit form is\[
        \frac{\mathrm{d}^{2}y}{\mathrm{d}x^{2}} = F\left(x,y,\frac{\mathrm{d}y}{\mathrm{d}x} \right) 
    \]
\end{General 2nd order ODE}

\begin{enumerate}[label = (\alph*)]
    \item $y, \frac{\mathrm{d}y}{\mathrm{d}x}$ \textbf{missing}, i.e. \[
            \frac{\mathrm{d}^{2}y}{\mathrm{d}x^{2}} = f(x)
    \]Just integrate twice!

\item $x, \frac{\mathrm{d}y}{\mathrm{d}x}$ \textbf{missing}, i.e. \[
        \frac{\mathrm{d}^{2}y}{\mathrm{d}x^{2}} = f(y)
\]
\underline{Warning}: Do not write $\frac{\mathrm{d}^{2}y}{\mathrm{d}x^{2}} = \frac{1}{\frac{\mathrm{d}^{2}x}{\mathrm{d}y^{2}} } $
\end{enumerate}







\chapter{Linear Algebra}

\newmdtheoremenv[style=defEnv]{column vector}[theorem]{Definition}
\begin{column vector}
    A \emph{column vector} ($n$-column vector) $\pmb{v}_n$ is a tuple of $n$ real numbers written as a single columnn, 
    with $a_1, a_2, a_3, \ldots, a_n \in \mathbb{R}$:\[
    \pmb{v}_n := 
    \begin{pmatrix}
        a_1 \\
        a_2 \\
        a_3 \\
        \vdots \\
        a_n
    \end{pmatrix}
    \]
\end{column vector}

\newmdtheoremenv[style=defEnv]{set of column vectors}[theorem]{Definition}
\begin{set of column vectors}
    $\mathbb{R}^{n}$ is the set of all column vectors of height $n$ whose entries are real numbers.
    In symbols:\[
        \mathbb{R}^{n} = \{
            \begin{pmatrix}
                    a_1\\
                    a_2\\
                    \vdots\\
                    a_n
            \end{pmatrix}
            : a_1, a_2, \ldots, a_n \in \mathbb{R}
        \} 
    \]
\end{set of column vectors}

\begin{ex}
    $\mathbb{R}^{2}$ can be seen as Euclidean plane. $\mathbb{R}^{3}$ can be seen as Euclidean space.
    \\\underline{Caution}: Our vectors always ``start'' at the origin.
\end{ex}

\newmdtheoremenv[style=defEnv]{zero vector}[theorem]{Definition}
\begin{zero vector}
    The \textbf{\emph{zero vector $\pmb{0}_n$}} is the height $n$-column vector all of whose entries are 0.
\end{zero vector}


\newmdtheoremenv[style=defEnv]{standard basis vector}[theorem]{Definition}
\begin{standard basis vector}
    The \textbf{\emph{standard basis vectors}} in $\mathbb{R}^{n}$ are the vectors\[
        \pmb{e}_1 = \begin{pmatrix}
                1\\
                0\\
                \vdots\\
                0
        \end{pmatrix}, \quad
        \pmb{e}_2 = \begin{pmatrix}
                0\\
                1\\
                \vdots\\
                0
        \end{pmatrix}, \quad \ldots, \quad
        \pmb{e}_n = \begin{pmatrix}
                0\\
                0\\
                \vdots\\
                1
        \end{pmatrix}
    \]
    i.e. $\pmb{e}_k$ is the vector with $k$th entry equal to 1 and all other entries equal to 0.
\end{standard basis vector}

\newmdtheoremenv{operations on column vectors}[theorem]{(Operations on column vectors) Definition}
\begin{operations on column vectors}
    Let \[
        \pmb{v} = \begin{pmatrix}
                v_1\\
                v_2\\
                \vdots\\
                v_n
        \end{pmatrix}, \quad
        \pmb{u} = \begin{pmatrix}
                u_1\\
                u_2\\
                \vdots\\
                u_n
            \end{pmatrix}
    \]
    be column vectors $\mathbb{R}^{n}$, and let $\lambda$ be a (real or complex) number.
    \begin{enumerate}[label = (\arabic*)]
        \item Addition on vectors in $\mathbb{R}^{n}$ is given by:\[
                \begin{pmatrix}
                        v_1 + u_1\\
                        v_2 + u_2\\
                        \vdots\\
                        v_n + u_n
                \end{pmatrix}
            \]$+ : \mathbb{R}^{n} \times \mathbb{R}^{n} \rightarrow \mathbb{R}^{n}$ (binary operatioin).
            $(\mathbb{R}^{n}, +)$ is a group.
        \item \textbf{\emph{Scalar multiplication}} $\lambda \pmb{v}$ on $\mathbb{R}^{n}$:\[
            \begin{pmatrix}
                    \lambda v_1\\
                    \lambda v_2\\
                    \vdots\\
                    \lambda v_n
            \end{pmatrix}
        \]$s : \mathbb{R} \times \mathbb{R}^{n} \rightarrow \mathbb{R}^{n}$, so not binary operation.
    \item \textbf{\emph{Dot product}} $v \cdot u$ is defined to be the number $v_1 u_1 + v_2 u_2 + \cdots + v_n u_n$.
            $\cdot : \mathbb{R}^{n} \times \mathbb{R}^{n} \rightarrow \mathbb{R}$, so not binary.
    \end{enumerate}
\end{operations on column vectors}

\begin{ex}
    Show that $(\mathbb{R}^{n}, +)$ is an Abelian group.
    \begin{itemize}
        \item Identity: $\pmb{0}_n$ ($v + \pmb{0}_n = \pmb{v}$)
        \item $-\pmb{v}$ are inverses, where \[
            -\pmb{v} := \begin{pmatrix}
                    -v_1\\
                    -v_2\\
                    \vdots\\
                    -v_n
            \end{pmatrix}
        \]
        \item associativity: $(\pmb{u} + \pmb{v}) + \pmb{w} = \pmb{u} + (\pmb{v} + \pmb{w})$.
        \item commutative: $\pmb{u} + \pmb{v} = \pmb{v} + \pmb{u}$
    \end{itemize}
    \underline{Caution}: $+$ only makes sense for vectors of the \emph{same size}.
    e.g. $\pmb{v} \cdot \pmb{0}_n = 0 \in \mathbb{R}$.
\end{ex}

\newmdtheoremenv[style=defEnv]{combination of add and scalar multi}[theorem]{Definition}
\begin{combination of add and scalar multi}
    let $\pmb{v}_1, \pmb{v}_2, \pmb{v}_3, \ldots, \pmb{v}_n \in \mathbb{R}^{n}, \lambda_1, \lambda_2, \lambda_3, \ldots, \lambda_n \in \mathbb{R}$,
    then \[
        \lambda_1 \pmb{v}_1 + \lambda_2 \pmb{v}_2 + \cdots + \lambda_n \pmb{v}_n
    \]is called a \textbf{\emph{linear combination}} of $\pmb{v}_1, \pmb{v}_2, \pmb{v}_3, \ldots, \pmb{v}_n$.
\end{combination of add and scalar multi}

\newmdtheoremenv[style=defEnv]{span of vectors}[theorem]{Definition}
\begin{span of vectors}
    The set of all linear combinatioins of a collection of vectors $\pmb{v}_1, \pmb{v}_2, \ldots, \pmb{v}_n$
    is called the \textbf{\emph{span}} of the vectors $\pmb{v}_1, \pmb{v}_2, \ldots, \pmb{v}_n$.
    \\Notation: 
    
    span$\left\{\pmb{v}_1, \pmb{v}_2,\ldots,\pmb{v}_n\right\} := 
    \left\{\lambda_1 \pmb{v}_1 + \lambda_2 \pmb{v}_2 + \cdots + \lambda_n \pmb{v}_n 
    | \lambda_1, \ldots, \lambda_n \in \mathbb{R}\right\}$
\end{span of vectors}

\begin{ex}
    compute the span of 
    \begin{itemize}
        \item $\{\pmb{e}_1, \pmb{e}_2\}$, $\pmb{e}_1, \pmb{e}_2 \in \mathbb{R}^2$.
            \[
                \textnormal{span}\{\pmb{e}_1, \pmb{e}_2\} 
                = \{\lambda_1 \pmb{e}_1 + \lambda_2 \pmb{e}_2 | \lambda_1, \lambda_2 \in \mathbb{R}\}
            = \{
                    \begin{pmatrix}
                            \lambda_1\\
                            \lambda_2
                    \end{pmatrix}
| \lambda_1, \lambda_2 \in\mathbb{R}\}\]

\item span$\left\{\begin{pmatrix}
        1\\
        0\\
        0
\end{pmatrix}
, \begin{pmatrix}
        0\\
        2\\
        0
\end{pmatrix}
\right\} = \{
\begin{pmatrix}
        \lambda_1\\
        2\lambda_2\\
        0
\end{pmatrix}
| \lambda_1, \lambda_2 \in \mathbb{R}
\}$
    \end{itemize}
    
\end{ex}

\newmdtheoremenv[style=defEnv]{length and norm}[theorem]{Definition}
\begin{length and norm}
    let $\pmb{v} \in \mathbb{R}^{n}$. The \textbf{\emph{length}} of $\pmb{v}$, a.k.a.\ the \textbf{\emph{norm}} 
    of $\pmb{v}$, is the non-negative real number $||\pmb{v}||$ defined by \[
        ||\pmb{v}|| = \sqrt{\pmb{v} \cdot \pmb{v}}
    \]
    \underline{Note}: $||\pmb{0}|| = 0$, and conversely if $\pmb{v} \neq 0$ then $||\pmb{v}|| > 0$.
    This definition agrees with out usual ideas about the length of a vector in $\mathbb{R}^{2}$
    or $\mathbb{R}^{3}$, which follows from Pythagoras' theorem.
\end{length and norm}

\newmdtheoremenv[style=defEnv]{unit vector}[theorem]{Definition}
\begin{unit vector}
    A vector $\pmb{v} \in \mathbb{R}^{n}$ is called a \textbf{\emph{unit vector}}
    if $||\pmb{v}|| = 1$.
\end{unit vector}

\smallskip
\begin{ex}
    \;

    \begin{enumerate}[label = (\arabic*)]
        \item Any non-zero vector $\pmb{v}$ can be made into a unit vector
            $u := \frac{\pmb{v}}{||\pmb{v}||}$. This process is called \textbf{\emph{normalizing}}.
        \item The standard basis vectors are unit vectors.
    \end{enumerate}
    
\end{ex}

\subsection{Basic Matrix Operations}

\newmdtheoremenv[style=defEnv]{matrix definition}[theorem]{Definition}
\begin{matrix definition}
    An $n \times m$-matrix is a rectangular grid of numbers called the \emph{entries} of the matrix
    with $n$ rows and $m$ columns. A real matrix is onne whose entries are real numbers,
    and a complex matrix is one whose entries are complex numbers.

    \underline{Notations}: $M_{n \times m}(\mathbb{R}), M_{n,m}(\mathbb{R}), \mbox{Mat}_{n\times m}(\mathbb{R}), \mathbb{R}^{n\times m}$.

\end{matrix definition}

\underline{Operations on matrices}:
\newmdtheoremenv[style=defEnv]{matrices operation}[theorem]{Definition}
\begin{matrices operation}
    let $A = (a_{ij})$ and $B = (b_{ij})$ are $n\times m$-matrix, $\lambda \in \mathbb{R}$. Then:
    \begin{enumerate}[label = (\arabic*)]
        \item $A+B = n\times m$-matrix $\,(a_{ij} + b_{ij})$.
            $+: M_{n \times m}(\mathbb{R}) \times M_{n \times m}(\mathbb{R}) \rightarrow M_{n \times m}(\mathbb{R})$
        \item $\lambda A = n \times m$-matrix $\,(\lambda a_{ij})$
    \end{enumerate}
    
\end{matrices operation}

\newmdtheoremenv[style=defEnv]{addition on matrix is Abelian}[theorem]{Theorem}
\begin{addition on matrix is Abelian}
    $(M_{n \times m}(\mathbb{R}), +)$ is an Abelian grouop.
\end{addition on matrix is Abelian}

\newmdtheoremenv[style=defEnv]{transpose}[theorem]{Definition}
\begin{transpose}
    The \emph{transpose} $A^{T}$ of an $n \times m$-matrix $(a_{ij})$ is 
    the $m \times n$-matrix $(a_{ij})$.
\end{transpose}

\newmdtheoremenv[style=defEnv]{multiplying matrix with vector}[theorem]{(Multiplying matrices with vectors) Definition}
\begin{multiplying matrix with vector}
    Let $A = (a_{ij})$ be an $n \times m$-matrix, $v \in \mathbb{R}^{m}$.
    Then $Av$ is the vector in $\mathbb{R}^{n}$ with $i$-th row entry $\sum_{j=1}^{m} a_{ij}v_j$
\end{multiplying matrix with vector}

\begin{ex}
    \begin{itemize}
            \item 
                Prove that for $A \in M_{n \times m}(\mathbb{R}), e_k \in \mathbb{R}^{m}$,
                $Ae_k = k$-th column of A.
    
                \underline{Proof}: let $A = (a_{ij})$. By definition the $i$-th entry of $Ae_k$ is\[
                    \sum_{j=1}^{m} a_{ij}{(e_k)}_j = a_{ik}
                \]since $ {(e_k)}_j = 0$ whenever $j \neq k$, 1 for $j = k$
            \item $\nu \cdot v = \nu^{T}v$
            \item Let $I_n$ be the identity matrix. Show formally that $I_n \nu = \nu$, $\forall \nu \in \mathbb{R}^{n}$.
            \item let $\nu_1, \nu_2, \nu_3 \in \mathbb{R}^{3}$.
                Write the linear combination $3\nu_1 - 5\nu_2 + 7\nu_3$ as a multiplication of matrix
                $A \in M_{3 \times 3}(\mathbb{R})$ with a vector $x \in \mathbb{R}^{3}$
    \end{itemize}
    
\end{ex}

\section{System of linear equations}

\newmdtheoremenv[style=defEnv]{linear equation}[theorem]{Definition}
\begin{linear equation}
    A \emph{linear equation} in the variables $x_1, x_2, \ldots, x_n \in \mathbb{R}$
    is an equation of the form:\[
        \lambda_1 x_1 + \lambda_2 x_2 + \cdots + \lambda_n x_n = c, 
        \,\textnormal{with }\, \lambda_1,\ldots,\lambda_n \subset \,\textnormal{\emph{Fixed} real numbers}
    \]
    \underline{Caution}: In particular, no powers/multiplications/function of one or more variables.
\end{linear equation}

\newmdtheoremenv[style=defEnv]{simultaneous list of linear equations}[theorem]{Definition}
\begin{simultaneous list of linear equations}
    A system of linnear equations is a simultaneous list of linear equations
\end{simultaneous list of linear equations}




\chapter{Analysis}


\end{document}
